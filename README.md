# Multi-label предсказание категорий трат (Kaggle, Top-15)

Автор: Татьяна Мерзлякова  
Kaggle: tatianamerzl
telegram: @tatiana_merzl

Репозиторий содержит решение для соревнования на Kaggle по **многомерному (multi-label) предсказанию категорий трат** клиента в заданный период.  

Для каждой комбинации  
`(client_pin_hash, period_start, day_period)`  
необходимо предсказать **набор из 32 категорий** (например, `supermarkety`, `fastfud`, `transport` и др.), в которых клиент с наибольшей вероятностью будет совершать траты.  

---

## 1. Основная идея решения

1. **Разделение этапов обработки данных и обучения модели.**  
   Сырые транзакции имеют большой объем, поэтому все агрегаты строятся с помесячной обработкой и использованием 30-дневного окна вокруг даты `period_start`.

2. **Формирование признаков на уровне “клиент–период–категория”.**  
   Для каждой тройки `(клиент, период, категория)` рассчитывается компактный набор признаков, описывающих недавнюю активность клиента по данной категории: частота, суммы, доли, свежесть использования и время суток.

3. **Многомерное предсказание через ансамбль one-vs-rest моделей.**  
   Для каждой из 32 категорий обучается отдельная модель CatBoost (бинарная классификация), которая предсказывает вероятность присутствия этой категории в целевом множестве.

4. **Категорийно-зависимые пороги.**  
   Для каждой категории отдельный порог по вероятности подбирается по валидационной выборке с учетом соревновательной метрики (близость к Jaccard / Hamming), а затем используется при инференсе на тесте.

5. **Формирование итогового сабмита.**  
   Предсказания всех 32 моделей объединяются в wide-формат и сохраняются в `submission_best.csv` в требуемом формате соревнования.

---

## 2. Используемые признаки

### 2.1. Поведенческие признаки по транзакциям (7 признаков на категорию)

Все признаки рассчитываются в окне **последних 30 дней до `period_start`** на основе истории транзакций (`df_trans.parquet`). Для каждой тройки `(клиент, период, категория)` формируются:

- **`f1_amount_share_30d`** — доля суммы трат по данной категории в общей сумме трат клиента за последние 30 дней.  

- **`f2_days_since_last_cat`** — количество дней с момента последней операции по данной категории до начала прогнозируемого периода.  
  Позволяет отделить регулярно используемые категории от давно неактивных.

- **`f3_halfdays_since_any`** — время с момента любой последней операции клиента, измеренное в условных «полуднях» (12-часовых интервалах).  
  Даёт грубую оценку общей активности клиента.

- **`f4_sum_amt_cat_30d`** — суммарная сумма по данной категории за 30 дней.  

- **`f5_cnt_cat_30d`** — количество транзакций по категории за 30 дней.  

- **`f6_cnt_share_30d`** — доля числа транзакций по категории в общем числе транзакций клиента за 30 дней.  

- **`f7_is_morning`** — бинарный признак, равный 1, если `day_period = "morning"`, и 0 в противном случае.  
  Позволяет учитывать различия в поведении клиентов в зависимости от части дня.

Эти признаки формируются в отдельном скрипте построения фичей и сохраняются в файлы  
`train_feat7_all.parquet` и `test_feat7_all.parquet`.

### 2.2. Профильные признаки клиента

Дополнительно используются профильные характеристики клиента, восстановленные из `train_*.parquet`:

- **`age`** — возраст клиента (среднее значение по всем записям клиента, где возраст указан).  

- **`seg`** — сегмент клиента (`clientsegment`).

### 2.3. Календарный признак

- **`dow_idx`** — день недели, вычисленный по `period_start` (целое значение от 0 до 6).  
  Позволяет учитывать различия поведения по дням недели.

Итоговый набор признаков, поступающий в модель:

- 7 поведенческих признаков клиента в конкретной категории `f1…f7`: частота, суммы, доли, свежесть использования,
- `age`, возраст
- `dow_idx`, день недели
- категориальный признак сегмента `seg`.

---

## 3. Модель CatBoost и схема обучения

### 3.1. Подход one-vs-rest

Для обучения используется ансамбль из **32 независимых моделей CatBoostClassifier**:

- для каждой категории `k` выбираются строки с соответствующим `cat_id = k`,
- таргет `y` равен 1, если категория присутствует в списке `target` для данной строки, и 0 — в противном случае,
- на этих данных обучается отдельная бинарная модель.

Такой подход упрощает:

- работу с сильным дисбалансом по редким категориям (можно настраивать веса по каждой категории),
- анализ качества и интерпретацию (каждая модель отвечает за одну категорию),
- последующий подбор порогов.

### 3.2. Набор признаков и типы

Для всех моделей используется одинаковый набор признаков:

- числовые: `f1…f7`, `age`, `dow_idx`;
- категориальные: `seg` (передаётся в CatBoost через `Pool(cat_features=[…])`).

### 3.3. Основные параметры CatBoost

Для каждой категории используется одинаковый базовый набор гиперпараметров:

- `task_type="GPU"` — обучение на GPU;
- `iterations ≈ 1200`;
- `depth = 7`;
- `learning_rate ≈ 0.06`;
- `loss_function = "Logloss"`;
- `eval_metric = "AUC"`;
- `used_ram_limit = "20gb"`.


### 3.4. Разбиение на выборки

Разбиение на обучающую, валидационную и внутреннюю тестовую выборки выполняется по клиентам, чтобы исключить утечки между сплитами:

- предварительно выбирается доля клиентов по hash-шардингу (`CLIENT_FRAC_P`, например 80%);
- далее используется `GroupShuffleSplit` с группировкой по `client_pin_hash`, чтобы все записи одного клиента попадали только в один сплит.

Так обеспечивается корректная оценка обобщающей способности моделей на новых клиентах.

---

## 4. Подбор порогов по вероятности

CatBoost для каждой категории возвращает не 0/1, а **вероятность** `p` того, что категория должна быть включена в ответ.  
Чтобы получить финальный набор меток, нужно для каждой категории выбрать порог `thr` и считать метку равной 1, если `p ≥ thr`.

В решении пороги подбираются **отдельно для каждой из 32 категорий** по валидационной выборке. Процедура состоит из двух шагов.

### 4.1. Начальное приближение порога (prevalence-init)

Сначала берётся **частота класса** на валидации для данной категории:

- если категория редкая (мало единиц), то разумно ожидать, что и высоких вероятностей должно быть немного;
- если категория встречается часто, порог должен быть ниже.

Технически это реализовано так:

1. на валидации считаются истинные метки `y_val` для категории и её среднее значение `prev` (доля единиц);
2. по предсказанным вероятностям `p_val` для этой категории берётся квантиль порядка `1 - prev`  
   (например, если доля единиц 0.1, берётся примерно 90-й перцентиль).

Так получается **стартовый порог** `T0`, согласованный с тем, насколько категория редкая или частая.

### 4.2. Уточнение порога на валидации

Далее порог **уточняется в окрестности** `T0`:

1. вокруг `T0` задаётся небольшой диапазон значений (например, `T0 ± 0.25`);
2. этот диапазон разбивается на несколько точек (равномерная сетка);
3. для каждого кандидата `t`:
   - вероятности `p_val` переводятся в 0/1 с порогом `t`,
   - считается качество на валидационной выборке с помощью вспомогательной метрики, которая учитывает совпадения и расхождения по меткам и хорошо коррелирует с соревновательной метрикой (Jaccard / Hamming);
4. выбирается тот порог `t`, при котором качество на валидации максимальное.

Такой поиск проводится по отдельности для каждой категории.  
Полученный набор порогов `thr[k]` затем используется при инференсе на тестовом наборе для перевода вероятностей в финальные бинарные предсказания по всем 32 категориям.

