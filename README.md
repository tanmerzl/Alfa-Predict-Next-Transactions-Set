# Alfa-Predict-Next-Transactions-Set

## Multi-label предсказание категорий трат (Kaggle, top-15)

Это решение для соревнования на Kaggle по **многометочному (multi-label) предсказанию категорий трат** клиента в заданный период.  
Финальный вариант вошёл в **топ-15** лидерборда.

Для каждой комбинации  
`(client_pin_hash, period_start, day_period)`  
нужно предсказать **набор из 32 категорий** (supermarkety, fastfud, transport и т.п.), в которых клиент будет тратить деньги.  
Метрика соревнования — Jaccard / IoU между истинным и предсказанным множествами категорий.

---

## 1. Основная идея решения

1. **Отдельно генерирую признаки, отдельно обучаю модель.**  
   Сырые транзакции очень большие, поэтому все тяжёлые агрегации делаю в DuckDB, помесячно и с 30-дневным окном вокруг даты `period_start`.

2. Для каждой пары  
   `(<клиент>, <период>, <категория>)`  
   считаю компактный набор признаков: как часто клиент пользовался этой категорией в последние 30 дней, какие суммы там крутятся, насколько она «свежая» и в какую часть дня мы прогнозируем.

3. Поверх этих признаков обучаю **отдельную CatBoost-модель** для каждой из 32 категорий (подход one-vs-rest).  
   На вход каждой модели идут одни и те же фичи, а таргет — «есть эта категория в target или нет».

4. Для каждой категории отдельно подбираю **порог вероятности**, который лучше всего согласуется с соревновательной метрикой на валидации.

5. На инференсе прогоняю тест через все 32 модели, собираю предсказания в wide-формат и формирую финальный `submission`.

---

## 2. Используемые признаки

### 2.1. Поведенческие признаки по транзакциям (7 штук)

Все они считаются в окне **последних 30 дней до `period_start`**:

- **`f1_amount_share_30d`** — доля суммы по этой категории в общей сумме трат клиента за 30 дней.  
  *Отвечает за то, насколько категория «важна» в структуре расходов.*

- **`f2_days_since_last_cat`** — сколько дней прошло с последней операции по этой категории.  
  *Показывает, насколько категория «свежая» или, наоборот, давно не использовалась.*

- **`f3_halfdays_since_any`** — сколько условных «полудней» (12-часовых интервалов) прошло с любой последней транзакции клиента.  
  *Грубый индикатор общей активности клиента.*

- **`f4_sum_amt_cat_30d`** — суммарная сумма по этой категории за 30 дней.  
  *Абсолютный объём трат по категории.*

- **`f5_cnt_cat_30d`** — количество транзакций по категории за 30 дней.  
  *Чистая частота использования категории.*

- **`f6_cnt_share_30d`** — доля числа транзакций по категории от общего числа транзакций за 30 дней.  
  *Насколько часто категория встречается среди всех покупок.*

- **`f7_is_morning`** — бинарный признак: 1, если `day_period = "morning"`, иначе 0.  
  *Учитывает, что поведение может отличаться утром, днём и вечером.*

Все эти признаки заранее считаются в отдельном скрипте и сохраняются в `train_feat7_all.parquet` / `test_feat7_all.parquet`.

### 2.2. Профильные признаки клиента

Дополнительно использую простый профиль клиента, собранный из `train_*.parquet`:

- **`age`** — средний возраст клиента (если в данных он присутствует).  
  Если возраст неизвестен, заполняю пропуск медианой возраста по данной категории.

- **`seg`** — сегмент клиента (`clientsegment`), приведённый к нижнему регистру.  
  Если сегмента нет, ставлю `'unknown'`. Эта фича идёт в CatBoost как **категориальная**.

### 2.3. Календарный признак

- **`dow_idx`** — день недели от 0 до 6, посчитанный из `period_start`.  
  *Позволяет отличать, например, будни и выходные.*

Итого, финальный набор признаков для модели:

- 7 поведенческих фичей `f1…f7`,
- плюс `age`,
- плюс `dow_idx`,
- плюс категориальный `seg`.

---

## 3. Модель CatBoost

### 3.1. One-vs-rest по 32 категориям

Вместо одной сложной multi-label модели использую ансамбль из **32 независимых CatBoostClassifier**:

- для каждой категории `c` беру строки с её `cat_id`,
- таргет `y = 1`, если эта категория присутствует в списке `target`, иначе `0`,
- обучаю отдельную модель с общим набором признаков.

Это даёт:

- возможность по-разному настраивать веса классов и пороги для редких/частых категорий,
- честную валидацию по каждой категории отдельно,
- простую интерпретацию: «эта модель отвечает только за категорию X».

### 3.2. Настройки CatBoost

Для всех категорий использую схожие параметры:

- `task_type="GPU"` — обучение на GPU;
- `iterations ≈ 1200`,
- `depth = 7`,
- `learning_rate ≈ 0.06`,
- `loss_function = "Logloss"`,
- `eval_metric = "AUC"`,
- `class_weights` — подбираются автоматически на основе дисбаланса класса и заранее заданного веса категории (чтобы редкие категории не терялись).

Признаки делю на:

- числовые (`f1…f7`, `age`, `dow_idx`),
- категориальные (`seg`), передаются через `Pool(cat_features=[…])`.

### 3.3. Разбиение и сэмплирование

Чтобы избежать утечки по клиентам:

- сначала выбираю часть клиентов по hash-шардингу (например, ~80%: `ABS(hash(client_id)) % 100 < 80`),
- затем для каждой категории:
  - делю данные на train / validation / internal test с помощью `GroupShuffleSplit`,
  - группой для сплитов выступает `client_pin_hash`, так что клиенты не пересекаются между сплитами.

---

## 4. Подбор порога для каждой категории

CatBoost возвращает **вероятность** класса `p` для каждой категории. Чтобы получить финальный бинарный ответ, нужно выбрать порог `thr`, начиная с которого мы считаем категорию «активной».

Я делаю это в два шага:

1. **Инициализация по распространённости класса (prevalence-init).**  
   - Сначала смотрю, какая доля единиц у категории на валидации (насколько категория редкая/частая).  
   - На основе этого беру разумный начальный порог: квантиль распределения предсказанных вероятностей, который примерно соответствует редкости класса.

2. **Уточнение порога вокруг начального значения.**  
   - Вокруг стартового порога строю небольшую сетку значений (например, ±0.25) и проверяю качество на валидации.
   - В качестве целевой метрики использую вариацию Hamming / Jaccard по этой категории: чем лучше совпадает предсказанный набор меток с истинным, тем лучше.
   - Выбираю порог, который даёт лучший результат на валидации.

Так для каждой из 32 категорий получается **свой порог** `thr[k]`.  
Именно эти пороги потом используются при инференсе на тесте при бинаризации вероятностей.

---

На этом уровне детализации README обычно достаточно: он показывает идею фичей, структуру модели и логику подбора порогов, не перегружая формулами и SQL. Если понадобится, можно отдельным разделом добавить «Как воспроизвести» с шагами запуска скриптов.
